{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306c6faa",
   "metadata": {},
   "source": [
    "# EarthArXiv Harvester "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from habanero import Crossref\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pyingest.serializers.classic import Tagged\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "cr = Crossref()\n",
    "doi_prefix = '10.31223'\n",
    "res = cr.prefixes(ids = doi_prefix, works = True, cursor = \"*\", limit = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for entry in res:\n",
    "    for item in entry['message']['items']:\n",
    "\n",
    "        def format_authors(authors_data):\n",
    "            formatted_authors = []\n",
    "            for author in authors_data:\n",
    "                last_name = author.get('family', '')\n",
    "                first_name = author.get('given', '')\n",
    "                if last_name and first_name:\n",
    "                    formatted_authors.append(f\"{last_name}, {first_name}\")\n",
    "                elif last_name and not first_name:\n",
    "                    formatted_authors.append(last_name)\n",
    "            return \"; \".join(formatted_authors)\n",
    "        \n",
    "        def format_affs(authors_data):\n",
    "            formatted_affs = []\n",
    "            for author in authors_data:\n",
    "                aff = author.get('affiliation', '')\n",
    "                orcid = author.get('ORCID', '').lstrip(\"http://orcid.org/\")\n",
    "                formatted_aff = \"\"\n",
    "                if aff:\n",
    "                    formatted_aff = f'{aff}'\n",
    "                if orcid:\n",
    "                    formatted_aff += f'<ID system=\\\"ORCID\\\">{orcid}</ID>'\n",
    "                formatted_affs.append(formatted_aff)\n",
    "            return \"; \".join(formatted_affs)\n",
    "\n",
    "        authors_data = item.get('author', [])\n",
    "        authors = format_authors(authors_data)\n",
    "        affiliations = format_affs(authors_data)\n",
    "        title = item.get('title', '')[0]\n",
    "        group_title = item.get('group-title', '')\n",
    "        abstract = item.get('abstract', '').replace(\"<jats:p>\", \"\").replace(\"</jats:p>\", \"\")\n",
    "        preprint_doi = item.get('DOI', '')\n",
    "        url = item.get('resource', {}).get('primary', {}).get('URL', '')\n",
    "        \n",
    "        links = \"\"\n",
    "        if preprint_doi:\n",
    "            links += f\"DOI: {preprint_doi}\"\n",
    "        if url:\n",
    "            links += f\"; ELECTR: {url}\"\n",
    "        links = links.lstrip(\"; \").rstrip(\"/\")\n",
    "        \n",
    "        pubdate = \"\"\n",
    "        if \"published\" in item and \"date-parts\" in item[\"published\"]:\n",
    "            date_parts = item[\"published\"][\"date-parts\"]\n",
    "            if date_parts:\n",
    "                year, month, day = date_parts[0]\n",
    "                pubdate = f\"{year}/{month:02d}/{day:02d}\"\n",
    "            \n",
    "        article_doi = \"\"\n",
    "        if \"relation\" in item and \"is-preprint-of\" in item[\"relation\"]:\n",
    "            is_preprint_of = item[\"relation\"][\"is-preprint-of\"]\n",
    "            if isinstance(is_preprint_of, list) and len(is_preprint_of) > 0:\n",
    "                article_doi = (is_preprint_of[0][\"id\"]).lstrip(\"https://doi.org/\")  \n",
    "    \n",
    "        if title != \"\":\n",
    "            r = {\n",
    "                \"authors\": \"; \".join(authors.split(\"; \")),\n",
    "                \"affiliations\": \"; \".join(affiliations.split(\"; \")),\n",
    "                \"pubdate\":pubdate,\n",
    "                \"title\": title,\n",
    "                \"properties\": links,\n",
    "                \"abstract\": abstract,\n",
    "                \"keywords\": group_title,\n",
    "                \"preprint_doi\": preprint_doi,\n",
    "                \"article_doi\": article_doi,\n",
    "                \"source\": \"CrossRef\"\n",
    "            }\n",
    "            records.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6df417",
   "metadata": {},
   "source": [
    "## Curation: Add new records to data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d273fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read master file from excel\n",
    "excel_file = \"eartharxiv_data.xlsx\"\n",
    "master_file = pd.read_excel(excel_file)\n",
    "\n",
    "# Create a set of preprint_dois were already harvested\n",
    "exclusions = set(master_file['preprint_doi'].tolist())\n",
    "\n",
    "# Create a list of the new records based on new preprint_dois\n",
    "records_to_add = []\n",
    "for r in records:\n",
    "    if r[\"preprint_doi\"] not in exclusions:\n",
    "        records_to_add.append(r)\n",
    "\n",
    "# Create a DataFrame from the new_records\n",
    "new_records_df = pd.DataFrame(records_to_add)\n",
    "original_df = pd.DataFrame(master_file)\n",
    "\n",
    "# Merge the new_records_df with the master_file to append the new records\n",
    "merged_df = pd.concat([original_df, new_records_df], ignore_index=True)\n",
    "\n",
    "# Write the merged DataFrame back to the master excel file\n",
    "merged_df.to_excel(excel_file, index=False)\n",
    "print(f\"Added {len(records_to_add)} records to {excel_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75025b49",
   "metadata": {},
   "source": [
    "## Curation: Generate tagged format records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84623767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA FROM EXCEL\n",
    "master_file = pd.read_excel(\"eartharxiv_data.xlsx\")\n",
    "dt = pd.DataFrame(master_file)\n",
    "\n",
    "json_output = \"eartharxiv.json\"\n",
    "tagged_output = \"eartharxiv.tag\"\n",
    "  \n",
    "# bibcodes = dt[\"bibcode\"].astype(str)\n",
    "authors = dt[\"authors\"].astype(str)\n",
    "affiliations = dt[\"affiliations\"].astype(str)\n",
    "titles = dt[\"title\"].astype(str)\n",
    "pubdates = dt[\"pubdate\"].astype(str)\n",
    "abstracts = dt[\"abstract\"].astype(str)\n",
    "links = dt[\"properties\"].astype(str)\n",
    "keywords = dt[\"keywords\"].astype(str)\n",
    "\n",
    "# lsR = [b if b != 'nan' else '' for b in bibcodes]\n",
    "lsA = [a if a != 'nan' else '' for a in authors]\n",
    "lsF = [a if a != 'nan' else '' for a in affiliations]\n",
    "lsT = [t if t != 'nan' else '' for t in titles]\n",
    "lsD = [d.replace('.0','') if d != 'nan' else '' for d in pubdates]\n",
    "lsI = [link if link != 'nan' else '' for link in links]\n",
    "lsB = [a if a != 'nan' else '' for a in abstracts]\n",
    "lsK = [k if k != 'nan' else '' for k in keywords]\n",
    "\n",
    "# ZIP TOGETHER RECORDS\n",
    "records = []\n",
    "for A, F, T, D, I, B, K in zip(lsA, lsF, lsT, lsD, lsI, lsB, lsK):\n",
    "#     if R == \"...................\":\n",
    "    records.append({\n",
    "                    \"bibcode\": \"\",\n",
    "                    \"authors\": A.split(\"; \"),\n",
    "                    \"affiliations\": F.split(\"; \"),\n",
    "                    \"pubdate\": D,\n",
    "                    \"title\": T,\n",
    "                    \"properties\": I,\n",
    "                    \"abstract\": B,\n",
    "                    \"keywords\": K,\n",
    "                    \"source\":\"CrossRef\"})\n",
    "\n",
    "# for r in records:\n",
    "#     html.unescape(r)\n",
    "    \n",
    "# SAVE JSON FILE\n",
    "with open(json_output, 'w') as outfile:\n",
    "    json.dump(records, outfile)\n",
    "print(f\"Saved {len(records)} records as {json_output}\")\n",
    "\n",
    "# Pyingest Serializer - Transform json into tagged format\n",
    "f = open(json_output)\n",
    "json_file = json.load(f)\n",
    "outputfp = open(tagged_output, 'a')\n",
    "for record in json_file:\n",
    "    serializer = Tagged()\n",
    "    serializer.write(record, outputfp)\n",
    "#     print(record,'\\n')\n",
    "print(f\"Saved {len(records)} records as {tagged_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97879d29",
   "metadata": {},
   "source": [
    "## Additional resolver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the Excel file into a DataFrame\n",
    "# master_file = pd.read_excel(\"eartharxiv_data.xlsx\")\n",
    "# dt = pd.DataFrame(master_file)\n",
    "\n",
    "# # Get rows with a bibcode value\n",
    "# rows_with_bibcode = dt[dt['bibcode'] != '...................']\n",
    "# count_with_bibcode = len(rows_with_bibcode)\n",
    "# print(f\"Rows with a bibcode: {count_with_bibcode}\")\n",
    "\n",
    "# # Get rows with no bibcode\n",
    "# rows_with_no_bibcode = dt[dt['bibcode'] == '...................']\n",
    "# count_no_bibcode = len(rows_with_no_bibcode)\n",
    "# print(f\"Rows with no bibcode: {count_no_bibcode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab19d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize an empty list for references\n",
    "# ref_list = []\n",
    "\n",
    "# # Iterate through rows with no bibcode\n",
    "# for index, row in rows_with_no_bibcode.iterrows():\n",
    "#     T = row[\"title\"]\n",
    "#     A = row[\"authors\"]\n",
    "#     doi = row[\"preprint_doi\"]\n",
    "    \n",
    "#     if A and T and doi:\n",
    "#         ref = {\n",
    "#             \"refstr\": f\"{A}, {T}, {doi}\",\n",
    "#             \"authors\": A,\n",
    "#             \"title\": T,\n",
    "#             \"doi\": doi\n",
    "#         }\n",
    "#     elif doi:\n",
    "#         ref = {\n",
    "#             \"refstr\": f\"{doi}\",\n",
    "#             \"doi\": doi\n",
    "#         }\n",
    "#     else:\n",
    "#         ref = {\"refstr\":\"\"}\n",
    "#     ref_string = json.dumps(ref, ensure_ascii=False)\n",
    "#     ref_list.append(ref_string)\n",
    "\n",
    "# # Reference Service API request, querying my 'references' list\n",
    "# # ADS Prod API Token\n",
    "# token = 'pHazHxvHjPVPAcotvj7DIijROZXUjG5vXa2OaCQO'\n",
    "# domain = 'https://api.adsabs.harvard.edu/v1/'\n",
    "# def resolve(references):\n",
    "#     payload = {'parsed_reference': references}\n",
    "#     response = requests.post(\n",
    "#         url = domain + 'reference/xml',\n",
    "#         headers = {'Authorization': 'Bearer ' + token,\n",
    "#                  'Content-Type': 'application/json',\n",
    "#                  'Accept':'application/json'},\n",
    "#         data = json.dumps(payload))\n",
    "#     if response.status_code == 200:\n",
    "#         return json.loads(response.content)['resolved'], 200\n",
    "#     else:\n",
    "#         print('From reference status_code is', response.status_code)\n",
    "#         return None, response.status_code\n",
    "\n",
    "# # Resolve my references, results in 'total results' list\n",
    "# references = [json.loads(ref) for ref in ref_list]\n",
    "# total_results = []\n",
    "# print('Querying %d references with the Reference Service ...'%len(references))\n",
    "# for i in range(0, len(references), 16):\n",
    "#     results, status = resolve(references[i:i+16])\n",
    "#     if results:\n",
    "#         total_results += results\n",
    "\n",
    "# # Save the results to excel\n",
    "# df = pd.DataFrame(total_results)\n",
    "# df.to_excel(\"ref_review.xlsx\", index=False)\n",
    "# print(\"Saved ref results to ref_review.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
